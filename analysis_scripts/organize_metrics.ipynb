{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import tableone\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_method = 'inf_phoenix'\n",
    "save_folder = 'results_m1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Derivation</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Validation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.96 (0.95, 0.96)</td>\n",
       "      <td>0.95 (0.95, 0.96)</td>\n",
       "      <td>0.93 (0.93, 0.94)</td>\n",
       "      <td>0.94 (0.94, 0.94)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.94 (0.94, 0.94)</td>\n",
       "      <td>0.94 (0.94, 0.94)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.78 (0.77, 0.78)</td>\n",
       "      <td>0.77 (0.77, 0.78)</td>\n",
       "      <td>0.7 (0.7, 0.71)</td>\n",
       "      <td>0.72 (0.71, 0.73)</td>\n",
       "      <td>0.74 (0.73, 0.74)</td>\n",
       "      <td>0.72 (0.71, 0.72)</td>\n",
       "      <td>0.69 (0.69, 0.7)</td>\n",
       "      <td>0.7 (0.7, 0.71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "      <td>0.85 (0.85, 0.85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.71 (0.71, 0.72)</td>\n",
       "      <td>0.71 (0.7, 0.71)</td>\n",
       "      <td>0.6 (0.59, 0.61)</td>\n",
       "      <td>0.62 (0.61, 0.63)</td>\n",
       "      <td>0.65 (0.65, 0.66)</td>\n",
       "      <td>0.62 (0.62, 0.63)</td>\n",
       "      <td>0.59 (0.58, 0.59)</td>\n",
       "      <td>0.6 (0.59, 0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.97 (0.96, 0.97)</td>\n",
       "      <td>0.96 (0.96, 0.97)</td>\n",
       "      <td>0.94 (0.94, 0.95)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUPRC</th>\n",
       "      <td>0.85 (0.85, 0.86)</td>\n",
       "      <td>0.85 (0.84, 0.85)</td>\n",
       "      <td>0.78 (0.78, 0.79)</td>\n",
       "      <td>0.8 (0.8, 0.81)</td>\n",
       "      <td>0.82 (0.82, 0.82)</td>\n",
       "      <td>0.8 (0.8, 0.81)</td>\n",
       "      <td>0.76 (0.76, 0.76)</td>\n",
       "      <td>0.78 (0.77, 0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.99 (0.99, 0.99)</td>\n",
       "      <td>0.99 (0.99, 0.99)</td>\n",
       "      <td>0.99 (0.99, 0.99)</td>\n",
       "      <td>0.99 (0.99, 0.99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.71 (0.71, 0.72)</td>\n",
       "      <td>0.71 (0.7, 0.71)</td>\n",
       "      <td>0.6 (0.59, 0.61)</td>\n",
       "      <td>0.62 (0.61, 0.63)</td>\n",
       "      <td>0.65 (0.65, 0.66)</td>\n",
       "      <td>0.62 (0.62, 0.63)</td>\n",
       "      <td>0.59 (0.58, 0.59)</td>\n",
       "      <td>0.6 (0.59, 0.6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Derivation                                        \\\n",
       "                      CatBoost            XGBoost                 LR   \n",
       "Accuracy     0.96 (0.95, 0.96)  0.95 (0.95, 0.96)  0.93 (0.93, 0.94)   \n",
       "F1-Score     0.78 (0.77, 0.78)  0.77 (0.77, 0.78)    0.7 (0.7, 0.71)   \n",
       "Recall       0.85 (0.85, 0.85)  0.85 (0.85, 0.85)  0.85 (0.85, 0.85)   \n",
       "Precision    0.71 (0.71, 0.72)   0.71 (0.7, 0.71)   0.6 (0.59, 0.61)   \n",
       "Specificity  0.97 (0.96, 0.97)  0.96 (0.96, 0.97)  0.94 (0.94, 0.95)   \n",
       "AUROC        0.98 (0.98, 0.98)  0.98 (0.98, 0.98)  0.97 (0.97, 0.97)   \n",
       "AUPRC        0.85 (0.85, 0.86)  0.85 (0.84, 0.85)  0.78 (0.78, 0.79)   \n",
       "NPV          0.98 (0.98, 0.98)  0.98 (0.98, 0.98)  0.98 (0.98, 0.98)   \n",
       "PPV          0.71 (0.71, 0.72)   0.71 (0.7, 0.71)   0.6 (0.59, 0.61)   \n",
       "\n",
       "                                       Validation                     \\\n",
       "                            RF           CatBoost            XGBoost   \n",
       "Accuracy     0.94 (0.94, 0.94)  0.95 (0.95, 0.95)  0.95 (0.95, 0.95)   \n",
       "F1-Score     0.72 (0.71, 0.73)  0.74 (0.73, 0.74)  0.72 (0.71, 0.72)   \n",
       "Recall       0.85 (0.85, 0.85)  0.85 (0.85, 0.85)  0.85 (0.85, 0.85)   \n",
       "Precision    0.62 (0.61, 0.63)  0.65 (0.65, 0.66)  0.62 (0.62, 0.63)   \n",
       "Specificity  0.95 (0.95, 0.95)  0.96 (0.96, 0.96)  0.96 (0.96, 0.96)   \n",
       "AUROC        0.97 (0.97, 0.97)  0.98 (0.98, 0.98)  0.98 (0.98, 0.98)   \n",
       "AUPRC          0.8 (0.8, 0.81)  0.82 (0.82, 0.82)    0.8 (0.8, 0.81)   \n",
       "NPV          0.98 (0.98, 0.98)  0.99 (0.99, 0.99)  0.99 (0.99, 0.99)   \n",
       "PPV          0.62 (0.61, 0.63)  0.65 (0.65, 0.66)  0.62 (0.62, 0.63)   \n",
       "\n",
       "                                                   \n",
       "                            LR                 RF  \n",
       "Accuracy     0.94 (0.94, 0.94)  0.94 (0.94, 0.94)  \n",
       "F1-Score      0.69 (0.69, 0.7)    0.7 (0.7, 0.71)  \n",
       "Recall       0.85 (0.85, 0.85)  0.85 (0.85, 0.85)  \n",
       "Precision    0.59 (0.58, 0.59)    0.6 (0.59, 0.6)  \n",
       "Specificity  0.95 (0.95, 0.95)  0.95 (0.95, 0.95)  \n",
       "AUROC        0.97 (0.97, 0.97)  0.97 (0.97, 0.97)  \n",
       "AUPRC        0.76 (0.76, 0.76)  0.78 (0.77, 0.78)  \n",
       "NPV          0.99 (0.99, 0.99)  0.99 (0.99, 0.99)  \n",
       "PPV          0.59 (0.58, 0.59)    0.6 (0.59, 0.6)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_internal = pd.read_csv(os.path.join('/home/dchanci/research/pediatric_sepsis/prediction_ml/models/results_updated', screening_method, save_folder, 'sum_metrics_holdout_fixed.csv'))\n",
    "metrics_internal = metrics_internal.T\n",
    "\n",
    "metrics_external = pd.read_csv(os.path.join('/home/dchanci/research/pediatric_sepsis/prediction_ml/models/results_updated', screening_method, save_folder, 'sum_metrics_external_fixed.csv'))\n",
    "metrics_external = metrics_external.T\n",
    "\n",
    "metrics_internal = pd.concat([metrics_internal, metrics_external], axis=1)\n",
    "metrics_internal.columns = metrics_internal.iloc[0]\n",
    "metrics_internal = metrics_internal.iloc[1:]\n",
    "metrics_internal.columns = [['Derivation', 'Derivation', 'Derivation', 'Derivation', 'Validation', 'Validation', 'Validation', 'Validation'], list(metrics_internal.columns)]\n",
    "\n",
    "metrics_internal.to_csv(os.path.join('/home/dchanci/research/pediatric_sepsis/prediction_ml/models/results_updated', screening_method, save_folder, 'sum_metrics_fixed.csv'))\n",
    "\n",
    "metrics_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Derivation</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Validation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.94 (0.94, 0.94)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.95 (0.95, 0.95)</td>\n",
       "      <td>0.96 (0.95, 0.96)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.77 (0.77, 0.77)</td>\n",
       "      <td>0.77 (0.76, 0.77)</td>\n",
       "      <td>0.72 (0.71, 0.72)</td>\n",
       "      <td>0.73 (0.73, 0.74)</td>\n",
       "      <td>0.75 (0.75, 0.75)</td>\n",
       "      <td>0.75 (0.75, 0.75)</td>\n",
       "      <td>0.71 (0.71, 0.72)</td>\n",
       "      <td>0.74 (0.73, 0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.87 (0.87, 0.88)</td>\n",
       "      <td>0.86 (0.85, 0.86)</td>\n",
       "      <td>0.8 (0.79, 0.81)</td>\n",
       "      <td>0.8 (0.8, 0.81)</td>\n",
       "      <td>0.79 (0.79, 0.8)</td>\n",
       "      <td>0.79 (0.79, 0.79)</td>\n",
       "      <td>0.78 (0.78, 0.79)</td>\n",
       "      <td>0.77 (0.77, 0.77)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.69 (0.68, 0.69)</td>\n",
       "      <td>0.7 (0.69, 0.7)</td>\n",
       "      <td>0.65 (0.64, 0.65)</td>\n",
       "      <td>0.67 (0.67, 0.68)</td>\n",
       "      <td>0.72 (0.71, 0.72)</td>\n",
       "      <td>0.71 (0.71, 0.72)</td>\n",
       "      <td>0.65 (0.65, 0.66)</td>\n",
       "      <td>0.71 (0.7, 0.71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.96 (0.95, 0.96)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.96 (0.96, 0.96)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "      <td>0.97 (0.97, 0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUPRC</th>\n",
       "      <td>0.85 (0.85, 0.86)</td>\n",
       "      <td>0.85 (0.84, 0.85)</td>\n",
       "      <td>0.78 (0.78, 0.79)</td>\n",
       "      <td>0.8 (0.8, 0.81)</td>\n",
       "      <td>0.81 (0.81, 0.82)</td>\n",
       "      <td>0.82 (0.81, 0.82)</td>\n",
       "      <td>0.76 (0.75, 0.76)</td>\n",
       "      <td>0.8 (0.79, 0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.99 (0.99, 0.99)</td>\n",
       "      <td>0.99 (0.98, 0.99)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "      <td>0.98 (0.98, 0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.69 (0.68, 0.69)</td>\n",
       "      <td>0.7 (0.69, 0.7)</td>\n",
       "      <td>0.65 (0.64, 0.65)</td>\n",
       "      <td>0.67 (0.67, 0.68)</td>\n",
       "      <td>0.72 (0.71, 0.72)</td>\n",
       "      <td>0.71 (0.71, 0.72)</td>\n",
       "      <td>0.65 (0.65, 0.66)</td>\n",
       "      <td>0.71 (0.7, 0.71)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Derivation                                        \\\n",
       "                      CatBoost            XGBoost                 LR   \n",
       "Accuracy     0.95 (0.95, 0.95)  0.95 (0.95, 0.95)  0.94 (0.94, 0.94)   \n",
       "F1-Score     0.77 (0.77, 0.77)  0.77 (0.76, 0.77)  0.72 (0.71, 0.72)   \n",
       "Recall       0.87 (0.87, 0.88)  0.86 (0.85, 0.86)   0.8 (0.79, 0.81)   \n",
       "Precision    0.69 (0.68, 0.69)    0.7 (0.69, 0.7)  0.65 (0.64, 0.65)   \n",
       "Specificity  0.96 (0.96, 0.96)  0.96 (0.96, 0.96)  0.96 (0.95, 0.96)   \n",
       "AUROC        0.98 (0.98, 0.98)  0.98 (0.98, 0.98)  0.97 (0.97, 0.97)   \n",
       "AUPRC        0.85 (0.85, 0.86)  0.85 (0.84, 0.85)  0.78 (0.78, 0.79)   \n",
       "NPV          0.99 (0.99, 0.99)  0.99 (0.98, 0.99)  0.98 (0.98, 0.98)   \n",
       "PPV          0.69 (0.68, 0.69)    0.7 (0.69, 0.7)  0.65 (0.64, 0.65)   \n",
       "\n",
       "                                       Validation                     \\\n",
       "                            RF           CatBoost            XGBoost   \n",
       "Accuracy     0.95 (0.95, 0.95)  0.96 (0.96, 0.96)  0.96 (0.96, 0.96)   \n",
       "F1-Score     0.73 (0.73, 0.74)  0.75 (0.75, 0.75)  0.75 (0.75, 0.75)   \n",
       "Recall         0.8 (0.8, 0.81)   0.79 (0.79, 0.8)  0.79 (0.79, 0.79)   \n",
       "Precision    0.67 (0.67, 0.68)  0.72 (0.71, 0.72)  0.71 (0.71, 0.72)   \n",
       "Specificity  0.96 (0.96, 0.96)  0.97 (0.97, 0.97)  0.97 (0.97, 0.97)   \n",
       "AUROC        0.97 (0.97, 0.97)  0.98 (0.98, 0.98)  0.98 (0.98, 0.98)   \n",
       "AUPRC          0.8 (0.8, 0.81)  0.81 (0.81, 0.82)  0.82 (0.81, 0.82)   \n",
       "NPV          0.98 (0.98, 0.98)  0.98 (0.98, 0.98)  0.98 (0.98, 0.98)   \n",
       "PPV          0.67 (0.67, 0.68)  0.72 (0.71, 0.72)  0.71 (0.71, 0.72)   \n",
       "\n",
       "                                                   \n",
       "                            LR                 RF  \n",
       "Accuracy     0.95 (0.95, 0.95)  0.96 (0.95, 0.96)  \n",
       "F1-Score     0.71 (0.71, 0.72)  0.74 (0.73, 0.74)  \n",
       "Recall       0.78 (0.78, 0.79)  0.77 (0.77, 0.77)  \n",
       "Precision    0.65 (0.65, 0.66)   0.71 (0.7, 0.71)  \n",
       "Specificity  0.96 (0.96, 0.96)  0.97 (0.97, 0.97)  \n",
       "AUROC        0.97 (0.97, 0.97)  0.97 (0.97, 0.97)  \n",
       "AUPRC        0.76 (0.75, 0.76)    0.8 (0.79, 0.8)  \n",
       "NPV          0.98 (0.98, 0.98)  0.98 (0.98, 0.98)  \n",
       "PPV          0.65 (0.65, 0.66)   0.71 (0.7, 0.71)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_internal = pd.read_csv(os.path.join('/home/dchanci/research/pediatric_sepsis/prediction_ml/models/results_updated', screening_method, save_folder, 'sum_metrics_holdout.csv'))\n",
    "metrics_internal = metrics_internal.T\n",
    "\n",
    "metrics_external = pd.read_csv(os.path.join('/home/dchanci/research/pediatric_sepsis/prediction_ml/models/results_updated', screening_method, save_folder, 'sum_metrics_external.csv'))\n",
    "metrics_external = metrics_external.T\n",
    "\n",
    "metrics_internal = pd.concat([metrics_internal, metrics_external], axis=1)\n",
    "metrics_internal.columns = metrics_internal.iloc[0]\n",
    "metrics_internal = metrics_internal.iloc[1:]\n",
    "metrics_internal.columns = [['Derivation', 'Derivation', 'Derivation', 'Derivation', 'Validation', 'Validation', 'Validation', 'Validation'], list(metrics_internal.columns)]\n",
    "\n",
    "metrics_internal.to_csv(os.path.join('/home/dchanci/research/pediatric_sepsis/prediction_ml/models/results_updated', screening_method, save_folder, 'sum_metrics.csv'))\n",
    "\n",
    "metrics_internal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
